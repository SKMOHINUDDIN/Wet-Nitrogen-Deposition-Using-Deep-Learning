{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d62594-8608-4d5f-88ed-1703287837c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, logging, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import xy\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "logging.getLogger(\"rasterio._err\").setLevel(logging.ERROR)\n",
    "\n",
    "# ===========================\n",
    "# ABSOLUTE PATHS\n",
    "# ===========================\n",
    "# Predictors (1970–2019) on/near 0.1°\n",
    "EDGAR_NOX_PATH  = r\"D:\\Sekh Mohinuddin\\PhD Work\\NOx_NH3_Conference\\2nd Objectives\\EDGAR\\EDGAR_Nox_1970_2019.tif\"\n",
    "EDGAR_NH3_PATH  = r\"D:\\Sekh Mohinuddin\\PhD Work\\NOx_NH3_Conference\\2nd Objectives\\EDGAR\\EDGAR_NH3_1970_2019.tif\"\n",
    "PPT_TIF         = r\"D:\\Sekh Mohinuddin\\PhD Work\\NOx_NH3_Conference\\2nd Objectives\\ppt\\TerraClimate_annual_ppt_1970_2019_masked.tif\"\n",
    "\n",
    "# Observation rasters (USA, Europe, China)\n",
    "USA_DIR = r\"D:\\Sekh Mohinuddin\\PhD Work\\NOx_NH3_Conference\\1st Objectives\\Global N deposition\\USA\\Deposition\\WetDIN_Total_asN\"\n",
    "USA_PATTERN = os.path.join(USA_DIR, \"WetDIN_{year}_asN.tif\")  # 1990..2019\n",
    "\n",
    "EU_DIR_A = r\"D:\\Sekh Mohinuddin\\PhD Work\\NOx_NH3_Conference\\1st Objectives\\Global N deposition\\Europe\"\n",
    "EU_PATTERN_A = os.path.join(EU_DIR_A, \"WDEP_Total_{year}_flipped.tif\")   # 1990..2004\n",
    "EU_DIR_B = r\"D:\\Sekh Mohinuddin\\PhD Work\\NOx_NH3_Conference\\1st Objectives\\Global N deposition\\Europe\\Wet N\"\n",
    "EU_PATTERN_B = os.path.join(EU_DIR_B, \"EMEP_WDEP_{year}.tif\")            # 2005..2019\n",
    "\n",
    "CN_DIR_BLOCKS = r\"D:\\Sekh Mohinuddin\\PhD Work\\NOx_NH3_Conference\\1st Objectives\\Global N deposition\\Inorganic Nitrogen deposition  database1.0\\NITROGEN1_1996-2015\\1996-2015\"\n",
    "CN_BLOCK_96_00 = os.path.join(CN_DIR_BLOCKS, \"DIN_1996_2000.tif\")\n",
    "CN_BLOCK_01_05 = os.path.join(CN_DIR_BLOCKS, \"DIN_2001_2005.tif\")\n",
    "CN_BLOCK_06_10 = os.path.join(CN_DIR_BLOCKS, \"DIN_2006_2010.tif\")\n",
    "CN_DIR_2011_2019 = r\"D:\\Sekh Mohinuddin\\PhD Work\\NOx_NH3_Conference\\1st Objectives\\Global N deposition\\Inorganic Nitrogen deposition  database1.0\\Inorganic Nitrogen deposition  database1.0\\Data File\\Wet N\"\n",
    "CN_PERYEAR_PATTERN = os.path.join(CN_DIR_2011_2019, \"{year}.tif\")        # 2011..2019\n",
    "\n",
    "# Region boundaries (USA, Europe). China mask from obs coverage.\n",
    "USA_BOUNDARY_SHP = r\"D:\\Sekh Mohinuddin\\PhD Work\\NOx_NH3_Conference\\1st Objectives\\Global N deposition\\USA\\USA_Mainland.shp\"\n",
    "EU_BOUNDARY_SHP  = r\"D:\\Sekh Mohinuddin\\PhD Work\\NOx_NH3_Conference\\1st Objectives\\Global N deposition\\Europe\\Europe\\Com_Europe_merged.shp\"\n",
    "\n",
    "# ===========================\n",
    "# OUTPUTS\n",
    "# ===========================\n",
    "OUTPUT_DIR   = r\"D:\\Sekh Mohinuddin\\PhD Work\\NOx_NH3_Conference\\2nd Objectives\\Outputs-5\"\n",
    "PLOTS_DIR    = os.path.join(OUTPUT_DIR, \"Plots_SingleModel\")\n",
    "MODELS_DIR   = os.path.join(OUTPUT_DIR, \"Models_SingleModel\")\n",
    "FINAL_DIR    = os.path.join(OUTPUT_DIR, \"SingleModel_Global_from_USA_EU_CHN\")\n",
    "for d in [OUTPUT_DIR, PLOTS_DIR, MODELS_DIR, FINAL_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# ===========================\n",
    "# CONSTANTS\n",
    "# ===========================\n",
    "START_YEAR = 1990\n",
    "END_YEAR   = 2019\n",
    "EDGAR_BASE_YEAR = 1970\n",
    "NODATA = np.float32(-9999.0)\n",
    "\n",
    "# Sampling caps (tune for compute)\n",
    "MAX_SAMPLES_PER_YEAR_PER_REGION = 150_000   # for training set build\n",
    "HELDOUT_FRAC = 0.2                           # for gating per-year R2 inside each region\n",
    "\n",
    "# ===========================\n",
    "# Helpers\n",
    "# ===========================\n",
    "def map_year_to_band(year, base): return int(year - base + 1)\n",
    "\n",
    "def _clean(a, nodata):\n",
    "    aa = a.astype(np.float64, copy=False)\n",
    "    if nodata is not None and np.isfinite(nodata): aa[aa == nodata] = np.nan\n",
    "    aa[(aa <= -1e19) | (aa >= 1e19)] = np.nan\n",
    "    return aa\n",
    "\n",
    "def read_band(fp, band_idx):\n",
    "    with rasterio.open(fp) as src:\n",
    "        if not (1 <= band_idx <= src.count):\n",
    "            raise ValueError(f\"{fp}: band {band_idx}/{src.count}\")\n",
    "        arr = src.read(band_idx)\n",
    "        return _clean(arr, src.nodata), src.transform, src.crs, src.profile\n",
    "\n",
    "def resample_to(arr, s_tx, s_crs, d_shape, d_tx, d_crs, method=\"bilinear\"):\n",
    "    resamp = {\"nearest\": Resampling.nearest, \"bilinear\": Resampling.bilinear, \"cubic\": Resampling.cubic}.get(method, Resampling.bilinear)\n",
    "    out = np.full(d_shape, np.nan, dtype=np.float64)\n",
    "    reproject(source=arr.astype(np.float64, copy=False),\n",
    "              destination=out,\n",
    "              src_transform=s_tx, src_crs=s_crs,\n",
    "              dst_transform=d_tx, dst_crs=d_crs,\n",
    "              src_nodata=np.nan, dst_nodata=np.nan,\n",
    "              resampling=resamp, num_threads=2)\n",
    "    out[(out <= -1e19) | (out >= 1e19)] = np.nan\n",
    "    return out\n",
    "\n",
    "def dissolve_to_single(gdf):\n",
    "    geom = unary_union([g for g in gdf.geometry if g is not None and not g.is_empty])\n",
    "    return gpd.GeoDataFrame(geometry=[geom], crs=gdf.crs)\n",
    "\n",
    "def rasterize_gdf(gdf, tx, crs, out_shape):\n",
    "    if gdf.crs != crs: gdf = gdf.to_crs(crs)\n",
    "    geom = unary_union([g for g in gdf.geometry if g is not None and not g.is_empty])\n",
    "    if geom is None or geom.is_empty:\n",
    "        return np.zeros(out_shape, dtype=bool)\n",
    "    return rasterize([(geom, 1)], out_shape=out_shape, transform=tx, fill=0, dtype='uint8').astype(bool)\n",
    "\n",
    "# ===========================\n",
    "# Build 0.1° template from EDGAR NOx 1990\n",
    "# ===========================\n",
    "with rasterio.open(EDGAR_NOX_PATH) as _src:\n",
    "    b1990 = map_year_to_band(1990, EDGAR_BASE_YEAR)\n",
    "    _tmpl, T_TX, T_CRS, T_PROF = read_band(EDGAR_NOX_PATH, b1990)\n",
    "    T_H, T_W = _tmpl.shape\n",
    "    TEMPLATE_PROFILE = T_PROF.copy()\n",
    "    TEMPLATE_PROFILE.update(count=1, dtype=rasterio.float32, nodata=NODATA)\n",
    "print(f\"[template] 0.1° grid: H={T_H}, W={T_W}, CRS={T_CRS}\")\n",
    "\n",
    "# ===========================\n",
    "# Predictors (to template)\n",
    "# ===========================\n",
    "def predictors_for_year(year):\n",
    "    b = map_year_to_band(year, EDGAR_BASE_YEAR)\n",
    "    nox, nx_tx, nx_crs, _ = read_band(EDGAR_NOX_PATH, b)\n",
    "    nh3, nh_tx, nh_crs, _ = read_band(EDGAR_NH3_PATH, b)\n",
    "    ppt, pp_tx, pp_crs, _ = read_band(PPT_TIF, b)\n",
    "    if (nox.shape != (T_H, T_W)) or (nx_tx != T_TX) or (nx_crs != T_CRS):\n",
    "        nox = resample_to(nox, nx_tx, nx_crs, (T_H, T_W), T_TX, T_CRS)\n",
    "    if (nh3.shape != (T_H, T_W)) or (nh_tx != T_TX) or (nh_crs != T_CRS):\n",
    "        nh3 = resample_to(nh3, nh_tx, nh_crs, (T_H, T_W), T_TX, T_CRS)\n",
    "    if (ppt.shape != (T_H, T_W)) or (pp_tx != T_TX) or (pp_crs != T_CRS):\n",
    "        ppt = resample_to(ppt, pp_tx, pp_crs, (T_H, T_W), T_TX, T_CRS)\n",
    "    # domain-safe clips\n",
    "    nox = np.clip(nox, 0, 1e7); nh3 = np.clip(nh3, 0, 1e7); ppt = np.clip(ppt, 0, 1e4)\n",
    "    return nox, nh3, ppt\n",
    "\n",
    "# ===========================\n",
    "# Observation rasters (to template) + China mask builder\n",
    "# ===========================\n",
    "def obs_for_year(year):\n",
    "    \"\"\"Return list of (obs_array_on_template, region_tag).\"\"\"\n",
    "    out = []\n",
    "\n",
    "    # USA\n",
    "    upath = USA_PATTERN.format(year=year)\n",
    "    if os.path.exists(upath):\n",
    "        arr, s_tx, s_crs, _ = read_band(upath, 1)\n",
    "        if (arr.shape != (T_H, T_W)) or (s_tx != T_TX) or (s_crs != T_CRS):\n",
    "            arr = resample_to(arr, s_tx, s_crs, (T_H, T_W), T_TX, T_CRS)\n",
    "        arr = np.clip(arr, 0, 1e3)\n",
    "        out.append((arr, \"USA\"))\n",
    "\n",
    "    # Europe\n",
    "    if 1990 <= year <= 2004:\n",
    "        epath = EU_PATTERN_A.format(year=year)\n",
    "    else:\n",
    "        epath = EU_PATTERN_B.format(year=year)\n",
    "    if os.path.exists(epath):\n",
    "        arr, s_tx, s_crs, _ = read_band(epath, 1)\n",
    "        if (arr.shape != (T_H, T_W)) or (s_tx != T_TX) or (s_crs != T_CRS):\n",
    "            arr = resample_to(arr, s_tx, s_crs, (T_H, T_W), T_TX, T_CRS)\n",
    "        arr = np.clip(arr, 0, 1e3)\n",
    "        out.append((arr, \"EUROPE\"))\n",
    "\n",
    "    # China\n",
    "    cpath = None\n",
    "    if 1996 <= year <= 2000 and os.path.exists(CN_BLOCK_96_00):\n",
    "        cpath = CN_BLOCK_96_00\n",
    "    elif 2001 <= year <= 2005 and os.path.exists(CN_BLOCK_01_05):\n",
    "        cpath = CN_BLOCK_01_05\n",
    "    elif 2006 <= year <= 2010 and os.path.exists(CN_BLOCK_06_10):\n",
    "        cpath = CN_BLOCK_06_10\n",
    "    elif 2011 <= year <= 2019:\n",
    "        per = CN_PERYEAR_PATTERN.format(year=year)\n",
    "        if os.path.exists(per): cpath = per\n",
    "    if cpath is not None:\n",
    "        arr, s_tx, s_crs, _ = read_band(cpath, 1)\n",
    "        if (arr.shape != (T_H, T_W)) or (s_tx != T_TX) or (s_crs != T_CRS):\n",
    "            arr = resample_to(arr, s_tx, s_crs, (T_H, T_W), T_TX, T_CRS)\n",
    "        arr = np.clip(arr, 0, 1e3)\n",
    "        out.append((arr, \"CHINA\"))\n",
    "\n",
    "    return out\n",
    "\n",
    "def china_mask_from_obs():\n",
    "    mask = np.zeros((T_H, T_W), dtype=bool)\n",
    "    for y in list(range(1996, 2011)) + list(range(2011, 2020)):\n",
    "        lst = obs_for_year(y)\n",
    "        for arr, tag in lst:\n",
    "            if tag == \"CHINA\":\n",
    "                mask |= np.isfinite(arr)\n",
    "    return mask\n",
    "\n",
    "# ===========================\n",
    "# Build region masks (USA/EU from polygons; China from obs coverage)\n",
    "# ===========================\n",
    "usa_gdf = dissolve_to_single(gpd.read_file(USA_BOUNDARY_SHP))\n",
    "eu_gdf  = dissolve_to_single(gpd.read_file(EU_BOUNDARY_SHP))\n",
    "\n",
    "with rasterio.open(EDGAR_NOX_PATH) as _src:\n",
    "    USA_MASK = rasterize_gdf(usa_gdf, T_TX, T_CRS, (T_H, T_W))\n",
    "    EU_MASK  = rasterize_gdf(eu_gdf,  T_TX, T_CRS, (T_H, T_W))\n",
    "CHN_MASK = china_mask_from_obs()\n",
    "REGION_MASKS = {\"USA\": USA_MASK, \"EUROPE\": EU_MASK, \"CHINA\": CHN_MASK}\n",
    "print(f\"[masks] USA={USA_MASK.sum()} px | EU={EU_MASK.sum()} px | CHN={CHN_MASK.sum()} px\")\n",
    "\n",
    "# ===========================\n",
    "# Build training set from observed pixels in three regions\n",
    "# ===========================\n",
    "def build_training_from_regions():\n",
    "    Xs, ys = [], []\n",
    "    year_tags = []\n",
    "    for year in range(START_YEAR, END_YEAR+1):\n",
    "        obs_list = obs_for_year(year)\n",
    "        if not obs_list:\n",
    "            continue\n",
    "        # predictors (aligned to template)\n",
    "        nox, nh3, ppt = predictors_for_year(year)\n",
    "        yrn = (year - 2000.0)/50.0\n",
    "\n",
    "        for arr, tag in obs_list:\n",
    "            mask = REGION_MASKS.get(tag, None)\n",
    "            if mask is None:\n",
    "                continue\n",
    "            valid = np.isfinite(arr) & np.isfinite(nox) & np.isfinite(nh3) & np.isfinite(ppt) & mask\n",
    "            r, c = np.where(valid)\n",
    "            if r.size == 0:\n",
    "                continue\n",
    "            take = min(MAX_SAMPLES_PER_YEAR_PER_REGION, r.size)\n",
    "            sel = np.random.choice(r.size, take, replace=False)\n",
    "            rr, cc = r[sel], c[sel]\n",
    "\n",
    "            # coords\n",
    "            lat = np.empty(take, float); lon = np.empty(take, float)\n",
    "            for i in range(take):\n",
    "                yy, xx = int(rr[i]), int(cc[i])\n",
    "                xlon, ylat = xy(T_TX, yy, xx, offset='center')\n",
    "                lon[i] = xlon; lat[i] = ylat\n",
    "\n",
    "            feats = np.column_stack([nox[rr,cc], nh3[rr,cc], ppt[rr,cc], lat, lon, np.full(take, yrn)])\n",
    "            targ  = arr[rr, cc].astype(np.float32)\n",
    "            Xs.append(feats.astype(np.float32)); ys.append(targ)\n",
    "            year_tags.append(np.full(take, year, dtype=np.int16))\n",
    "        print(f\"[train-build] {year}: collected {sum(len(y) for y in ys)} samples so far\")\n",
    "\n",
    "    if not Xs:\n",
    "        raise RuntimeError(\"No training samples found; check observation raster paths.\")\n",
    "    X = np.vstack(Xs)\n",
    "    y = np.concatenate(ys)\n",
    "    yt = np.concatenate(year_tags)\n",
    "    print(f\"[train-build] Total samples: {X.shape[0]:,}\")\n",
    "    return X, y, yt\n",
    "\n",
    "def build_mlp(n_in):\n",
    "    m = keras.Sequential([\n",
    "        layers.Dense(384, activation='relu', input_shape=(n_in,)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.35),\n",
    "        layers.Dense(192, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Dense(96, activation='relu'),\n",
    "        layers.Dropout(0.15),\n",
    "        layers.Dense(48, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    m.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse', metrics=['mae','mse'])\n",
    "    return m\n",
    "\n",
    "# ===========================\n",
    "# Train single model + Gate (per-region R² by year)\n",
    "# ===========================\n",
    "def train_single_and_gate():\n",
    "    X, y, y_year = build_training_from_regions()\n",
    "    sx, sy = StandardScaler(), StandardScaler()\n",
    "    Xs, ys_ = sx.fit_transform(X), sy.fit_transform(y.reshape(-1,1))\n",
    "\n",
    "    model = build_mlp(X.shape[1])\n",
    "    cbs = [\n",
    "        keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True, verbose=1),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=8, verbose=1),\n",
    "        keras.callbacks.ModelCheckpoint(os.path.join(MODELS_DIR, \"single_best.h5\"), save_best_only=True, verbose=1),\n",
    "    ]\n",
    "    print(\"[single-train] fitting...\")\n",
    "    model.fit(Xs, ys_, epochs=200, batch_size=1024, validation_split=0.2, verbose=1, callbacks=cbs)\n",
    "    model.save(os.path.join(MODELS_DIR, \"single_final.h5\"))\n",
    "\n",
    "    # Gate: for each region+year where obs exists, evaluate R² on a held-out 20% random pixel set\n",
    "    gate_records = []\n",
    "    for region_name, region_mask in REGION_MASKS.items():\n",
    "        r2_per_year = []\n",
    "        for year in range(START_YEAR, END_YEAR+1):\n",
    "            # Load obs for this region+year\n",
    "            obs_arr = None\n",
    "            for arr, tag in obs_for_year(year):\n",
    "                if tag == region_name:\n",
    "                    obs_arr = arr; break\n",
    "            if obs_arr is None:\n",
    "                continue\n",
    "\n",
    "            nox, nh3, ppt = predictors_for_year(year)\n",
    "            valid = np.isfinite(obs_arr) & np.isfinite(nox) & np.isfinite(nh3) & np.isfinite(ppt) & region_mask\n",
    "            r, c = np.where(valid)\n",
    "            if r.size < 400:\n",
    "                continue\n",
    "            take = max(400, int(HELDOUT_FRAC * r.size))\n",
    "            sel = np.random.choice(r.size, take, replace=False)\n",
    "            rr, cc = r[sel], c[sel]\n",
    "\n",
    "            lat = np.empty(take, float); lon = np.empty(take, float)\n",
    "            for i in range(take):\n",
    "                yy, xx = int(rr[i]), int(cc[i])\n",
    "                xlon, ylat = xy(T_TX, yy, xx, offset='center')\n",
    "                lon[i] = xlon; lat[i] = ylat\n",
    "            yrn = (year - 2000.0)/50.0\n",
    "            Xte = np.column_stack([nox[rr,cc], nh3[rr,cc], ppt[rr,cc], lat, lon, np.full(take, yrn)])\n",
    "\n",
    "            pred = sy.inverse_transform(model.predict(sx.transform(Xte), verbose=0, batch_size=4096)).ravel()\n",
    "            r2 = r2_score(obs_arr[rr,cc], pred)\n",
    "            r2_per_year.append((year, r2))\n",
    "\n",
    "        if r2_per_year:\n",
    "            yrs, vals = zip(*r2_per_year)\n",
    "            mean_r2 = float(np.nanmean(vals))\n",
    "            gate_records.append((region_name, mean_r2))\n",
    "            # quick plot\n",
    "            plt.figure(figsize=(8,3))\n",
    "            plt.plot(yrs, vals, marker='o'); plt.grid(True)\n",
    "            plt.ylim(0, 1.0)\n",
    "            plt.title(f\"Gate R² by year — {region_name}\")\n",
    "            plt.xlabel(\"Year\"); plt.ylabel(\"R² (obs vs single-model)\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(PLOTS_DIR, f\"gate_r2_{region_name}.png\"), dpi=200)\n",
    "            plt.close()\n",
    "            pd.DataFrame(r2_per_year, columns=[\"year\",\"r2\"]).to_csv(\n",
    "                os.path.join(PLOTS_DIR, f\"gate_r2_{region_name}.csv\"), index=False)\n",
    "\n",
    "    df_gate = pd.DataFrame(gate_records, columns=[\"region\",\"mean_r2\"])\n",
    "    df_gate.to_csv(os.path.join(PLOTS_DIR, \"gate_summary.csv\"), index=False)\n",
    "    print(df_gate)\n",
    "\n",
    "    all_ok = True\n",
    "    for _, mean_r2 in gate_records:\n",
    "        if not (np.isfinite(mean_r2) and mean_r2 >= 0.85):\n",
    "            all_ok = False\n",
    "            break\n",
    "\n",
    "    # persist scalers\n",
    "    with open(os.path.join(MODELS_DIR, \"single_scalers.json\"), \"w\") as f:\n",
    "        json.dump({\"sx_mean\": sx.mean_.tolist(), \"sx_scale\": sx.scale_.tolist(),\n",
    "                   \"sy_mean\": float(sy.mean_[0]), \"sy_scale\": float(sy.scale_[0])}, f)\n",
    "    return model, sx, sy, all_ok\n",
    "\n",
    "# ===========================\n",
    "# Predict global seamless series\n",
    "# ===========================\n",
    "def predict_single_year(model, sx, sy, year, block=500):\n",
    "    nox, nh3, ppt = predictors_for_year(year)\n",
    "    out = np.full((T_H, T_W), np.nan, np.float32)\n",
    "    for r0 in range(0, T_H, block):\n",
    "        for c0 in range(0, T_W, block):\n",
    "            r1, c1 = min(T_H, r0+block), min(T_W, c0+block)\n",
    "            nb, hb, pb = nox[r0:r1, c0:c1], nh3[r0:r1, c0:c1], ppt[r0:r1, c0:c1]\n",
    "            v = np.isfinite(nb) & np.isfinite(hb) & np.isfinite(pb)\n",
    "            if not v.any(): continue\n",
    "            rr, cc = np.where(v)\n",
    "            lat = np.empty(rr.size, float); lon = np.empty(rr.size, float)\n",
    "            for i in range(rr.size):\n",
    "                yy, xx = r0+int(rr[i]), c0+int(cc[i])\n",
    "                xlon, ylat = xy(T_TX, yy, xx, offset='center')\n",
    "                lon[i] = xlon; lat[i] = ylat\n",
    "            yrn = (year - 2000.0)/50.0\n",
    "            feats = np.column_stack([nb[rr,cc], hb[rr,cc], pb[rr,cc], lat, lon, np.full(rr.size, yrn)])\n",
    "            pred = sy.inverse_transform(model.predict(sx.transform(feats), verbose=0, batch_size=4096)).ravel()\n",
    "            out[r0:r1, c0:c1][v] = pred.astype(np.float32)\n",
    "    # physical clamp\n",
    "    out = np.clip(out, 0, np.nanmax(out))\n",
    "    return out\n",
    "\n",
    "def write_single_series(model, sx, sy, start=START_YEAR, end=END_YEAR):\n",
    "    prof = TEMPLATE_PROFILE.copy()\n",
    "    for year in range(start, end+1):\n",
    "        print(f\"[predict] {year}\")\n",
    "        pred = predict_single_year(model, sx, sy, year)\n",
    "        out = np.where(np.isfinite(pred), pred, NODATA).astype(np.float32)\n",
    "        p = os.path.join(FINAL_DIR, f\"SingleModel_Global_0p1_{year}.tif\")\n",
    "        with rasterio.open(p, \"w\", **prof) as dst:\n",
    "            dst.write(out, 1)\n",
    "\n",
    "# ===========================\n",
    "# MAIN\n",
    "# ===========================\n",
    "def main():\n",
    "    print(\"=== Single-model (USA+EU+CHN only) → Global prediction (1990–2019) ===\")\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for g in gpus:\n",
    "                tf.config.experimental.set_memory_growth(g, True)\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "\n",
    "    model, sx, sy, gate_ok = train_single_and_gate()\n",
    "    if not gate_ok:\n",
    "        print(\"[STOP] Gate failed — mean R² < 0.85 in at least one region. Not writing outputs.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n=== Gate passed in USA, EUROPE, CHINA (mean R² ≥ 0.85). Writing seamless global GTiffs ===\")\n",
    "    write_single_series(model, sx, sy, START_YEAR, END_YEAR)\n",
    "\n",
    "    print(\"\\nDONE\")\n",
    "    print(f\"Seamless single-model outputs: {FINAL_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
